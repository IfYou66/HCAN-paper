{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from tsai.all import *\n",
    "import sklearn.metrics as skm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def seed_all(seed=23):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all(2025)"
   ],
   "id": "a0ba4191c1fb81e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2dfee3910f1c7ff3",
   "metadata": {},
   "source": [
    "df1 = pd.read_csv(r\".\\dataset\\damage_detection_Vänersborg\\type00.csv\", index_col=0)\n",
    "df2 = pd.read_csv(r\".\\dataset\\damage_detection_Vänersborg\\type01.csv\", index_col=0)\n",
    "df3 = pd.read_csv(r\".\\dataset\\damage_detection_Vänersborg\\type02.csv\", index_col=0)\n",
    "\n",
    "# ——— 显式滑窗划分 ———\n",
    "def sliding_windows(data: np.ndarray, window_size:int, step:int):\n",
    "    windows = []\n",
    "    for start in range(0, len(data) - window_size + 1, step):\n",
    "        windows.append(data[start:start+window_size])\n",
    "    return np.stack(windows)\n",
    "\n",
    "window_size = 500\n",
    "step        = 250   # 50% 重叠\n",
    "\n",
    "all_X, all_y = [], []\n",
    "for df, label in [(df1,0),(df2,1),(df3,2)]:\n",
    "    arr = df.values               # (T, 3)\n",
    "    W   = sliding_windows(arr, window_size, step)\n",
    "    all_X.append(W)               # (Nw, 500, 3)\n",
    "    all_y += [label] * W.shape[0]\n",
    "\n",
    "X = np.concatenate(all_X, axis=0)  # (总窗口数, 500, 3)\n",
    "y = np.array(all_y)                # (总窗口数,)\n",
    "\n",
    "# 转为 tsai 需要的形状 (N, c_in, seq_len)\n",
    "X = np.transpose(X, (0, 2, 1))     # (N, 3, 500)\n",
    "\n",
    "\n",
    "splits = get_splits(y, n_splits=1, valid_size=0.25, test_size=0, train_only=False,\n",
    "                    show_plot=True, check_splits=True, stratify=True, random_state=23, shuffle=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "id": "9b38da391b4ad1c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca762b06",
   "metadata": {},
   "source": [
    "# --- 位置编码模块 ---\n",
    "class tAPE(nn.Module):\n",
    "    \"time Absolute Position Encoding\"\n",
    "    def __init__(self, d_model:int, seq_len=1024, dropout:float=0.1, scale_factor=1.0):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin((position * div_term) * (d_model/seq_len))\n",
    "        pe[:, 1::2] = torch.cos((position * div_term) * (d_model/seq_len))\n",
    "        pe = scale_factor * pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    def forward(self, x):  # x: [batch, seq_len, d_model]\n",
    "        x = x + self.pe\n",
    "        return self.dropout(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b28f779",
   "metadata": {},
   "source": [
    "class AbsolutePositionalEncoding(nn.Module):\n",
    "    \"Absolute positional encoding\"\n",
    "    def __init__(self, d_model:int, seq_len=1024, dropout:float=0.1, scale_factor=1.0):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = scale_factor * pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe\n",
    "        return self.dropout(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13e6c299",
   "metadata": {},
   "source": [
    "class LearnablePositionalEncoding(nn.Module):\n",
    "    \"Learnable positional encoding\"\n",
    "    def __init__(self, d_model:int, seq_len=1024, dropout:float=0.1):\n",
    "        super().__init__()\n",
    "        self.pe = nn.Parameter(torch.empty(seq_len, d_model))\n",
    "        nn.init.uniform_(self.pe, -0.02, 0.02)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe\n",
    "        return self.dropout(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "78e137f1",
   "metadata": {},
   "source": [
    "# --- 多头自注意力模块 ---\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model:int, n_heads:int=8, dropout:float=0.01):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = d_model ** -0.5\n",
    "        self.key = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.query = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.to_out = nn.LayerNorm(d_model)\n",
    "    def forward(self, x):  # x: [batch, seq_len, d_model]\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        k = self.key(x).reshape(batch_size, seq_len, self.n_heads, -1).permute(0, 2, 3, 1)\n",
    "        v = self.value(x).reshape(batch_size, seq_len, self.n_heads, -1).transpose(1, 2)\n",
    "        q = self.query(x).reshape(batch_size, seq_len, self.n_heads, -1).transpose(1, 2)\n",
    "        attn = torch.matmul(q, k) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = out.transpose(1, 2).reshape(batch_size, seq_len, -1)\n",
    "        out = self.to_out(out)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22e72a1e",
   "metadata": {},
   "source": [
    "class Attention_Rel_Scl(nn.Module):\n",
    "    def __init__(self, d_model:int, seq_len:int, n_heads:int=8, dropout:float=0.01):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = d_model ** -0.5\n",
    "        self.key = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.query = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.relative_bias_table = nn.Parameter(torch.zeros((2 * self.seq_len - 1), n_heads))\n",
    "        coords = torch.meshgrid((torch.arange(1), torch.arange(self.seq_len)), indexing=\"xy\")\n",
    "        coords = torch.flatten(torch.stack(coords), 1)\n",
    "        relative_coords = coords[:, :, None] - coords[:, None, :]\n",
    "        relative_coords[1] += self.seq_len - 1\n",
    "        relative_coords = relative_coords.permute(1, 2, 0)\n",
    "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n",
    "        self.register_buffer(\"relative_index\", relative_index)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.to_out = nn.LayerNorm(d_model)\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        k = self.key(x).reshape(batch_size, seq_len, self.n_heads, -1).permute(0, 2, 3, 1)\n",
    "        v = self.value(x).reshape(batch_size, seq_len, self.n_heads, -1).transpose(1, 2)\n",
    "        q = self.query(x).reshape(batch_size, seq_len, self.n_heads, -1).transpose(1, 2)\n",
    "        attn = torch.matmul(q, k) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        relative_bias = self.relative_bias_table.gather(0, self.relative_index.repeat(1, self.n_heads))\n",
    "        relative_bias = relative_bias.reshape(self.seq_len, self.seq_len, -1).permute(2, 0, 1).unsqueeze(0)\n",
    "        attn = attn + relative_bias\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = out.transpose(1, 2).reshape(batch_size, seq_len, -1)\n",
    "        out = self.to_out(out)\n",
    "        return out\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce9b28e7",
   "metadata": {},
   "source": [
    "class Attention_Rel_Vec(nn.Module):\n",
    "    def __init__(self, d_model:int, seq_len:int, n_heads:int=8, dropout:float=0.01):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = d_model ** -0.5\n",
    "        self.key = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.query = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.Er = nn.Parameter(torch.randn(self.seq_len, int(d_model/n_heads)))\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(self.seq_len, self.seq_len)).unsqueeze(0).unsqueeze(0))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.to_out = nn.LayerNorm(d_model)\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        k = self.key(x).reshape(batch_size, seq_len, self.n_heads, -1).permute(0, 2, 3, 1)\n",
    "        v = self.value(x).reshape(batch_size, seq_len, self.n_heads, -1).transpose(1, 2)\n",
    "        q = self.query(x).reshape(batch_size, seq_len, self.n_heads, -1).transpose(1, 2)\n",
    "        QEr = torch.matmul(q, self.Er.transpose(0, 1))\n",
    "        Srel = self.skew(QEr)\n",
    "        attn = torch.matmul(q, k)\n",
    "        attn = (attn + Srel) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = out.transpose(1, 2).reshape(batch_size, seq_len, -1)\n",
    "        out = self.to_out(out)\n",
    "        return out\n",
    "    def skew(self, QEr):\n",
    "        padded = F.pad(QEr, (1, 0))\n",
    "        batch_size, n_heads, num_rows, num_cols = padded.shape\n",
    "        reshaped = padded.reshape(batch_size, n_heads, num_cols, num_rows)\n",
    "        Srel = reshaped[:, :, 1:, :]\n",
    "        return Srel"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc7a2d0a",
   "metadata": {},
   "source": [
    "# --- 定义网络骨干 ---\n",
    "class ConvTranBackbone(nn.Module):\n",
    "    def __init__(self, c_in:int, seq_len:int, d_model=16, n_heads:int=8, dim_ff:int=256,\n",
    "                 abs_pos_encode:str='tAPE', rel_pos_encode:str='eRPE', dropout:float=0.01):\n",
    "        super().__init__()\n",
    "        # 卷积嵌入层：先将输入扩展为 [batch, 1, c_in, seq_len]，再进行卷积操作\n",
    "        self.embed_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, d_model*4, kernel_size=[1, 7], padding='same'),\n",
    "            nn.BatchNorm2d(d_model*4),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.embed_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(d_model*4, d_model, kernel_size=[c_in, 1], padding='valid'),\n",
    "            nn.BatchNorm2d(d_model),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        # 选择绝对位置编码方式\n",
    "        assert abs_pos_encode in ['tAPE', 'sin', 'learned', None]\n",
    "        if abs_pos_encode == 'tAPE':\n",
    "            self.abs_position = tAPE(d_model, dropout=dropout, seq_len=seq_len)\n",
    "        elif abs_pos_encode == 'sin':\n",
    "            self.abs_position = AbsolutePositionalEncoding(d_model, dropout=dropout, seq_len=seq_len)\n",
    "        elif abs_pos_encode== 'learned':\n",
    "            self.abs_position = LearnablePositionalEncoding(d_model, dropout=dropout, seq_len=seq_len)\n",
    "        else:\n",
    "            self.abs_position = nn.Identity()\n",
    "        # 选择相对位置编码/注意力实现\n",
    "        assert rel_pos_encode in ['eRPE', 'vector', None]\n",
    "        if rel_pos_encode == 'eRPE':\n",
    "            self.attention_layer = Attention_Rel_Scl(d_model, seq_len, n_heads=n_heads, dropout=dropout)\n",
    "        elif rel_pos_encode == 'vector':\n",
    "            self.attention_layer = Attention_Rel_Vec(d_model, seq_len, n_heads=n_heads, dropout=dropout)\n",
    "        else:\n",
    "            self.attention_layer = Attention(d_model, n_heads=n_heads, dropout=dropout)\n",
    "        self.LayerNorm = nn.LayerNorm(d_model, eps=1e-5)\n",
    "        self.LayerNorm2 = nn.LayerNorm(d_model, eps=1e-5)\n",
    "        self.FeedForward = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_ff, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):  # x: [batch, c_in, seq_len]\n",
    "        x = x.unsqueeze(1)  # [batch, 1, c_in, seq_len]\n",
    "        x_src = self.embed_layer(x)\n",
    "        x_src = self.embed_layer2(x_src).squeeze(2)  # [batch, d_model, seq_len]\n",
    "        x_src = x_src.permute(0, 2, 1)  # [batch, seq_len, d_model]\n",
    "        x_src_pos = self.abs_position(x_src)\n",
    "        att = x_src + self.attention_layer(x_src_pos)\n",
    "        att = self.LayerNorm(att)\n",
    "        out = att + self.FeedForward(att)\n",
    "        out = self.LayerNorm2(out)\n",
    "        out = out.permute(0, 2, 1)  # [batch, d_model, seq_len]\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class lin_nd_head(nn.Sequential):\n",
    "    \"Module to create a nd output head with linear layers\"\n",
    "\n",
    "    def __init__(self, n_in, n_out, seq_len=None, d=None, flatten=False, use_bn=False, fc_dropout=0.):\n",
    "\n",
    "        if seq_len is None:\n",
    "            seq_len = 1\n",
    "        if d is None:\n",
    "            fd = 1\n",
    "            shape = [n_out]\n",
    "        elif is_listy(d):\n",
    "            fd = 1\n",
    "            shape = []\n",
    "            for _d in d:\n",
    "                fd *= _d\n",
    "                shape.append(_d)\n",
    "            if n_out > 1: shape.append(n_out)\n",
    "        else: \n",
    "            fd = d\n",
    "            shape = [d, n_out] if n_out > 1 else [d]\n",
    "            \n",
    "        layers = []\n",
    "        if use_bn:\n",
    "            layers += [nn.BatchNorm1d(n_in)]\n",
    "        if fc_dropout:\n",
    "            layers += [nn.Dropout(fc_dropout)]\n",
    "        if d is None:\n",
    "            if not flatten or seq_len == 1:\n",
    "                layers += [nn.AdaptiveAvgPool1d(1), Squeeze(-1), nn.Linear(n_in, n_out)]\n",
    "                if n_out == 1:\n",
    "                    layers += [Squeeze(-1)]\n",
    "            else:\n",
    "                layers += [Reshape(), nn.Linear(n_in * seq_len, n_out * fd)]\n",
    "                if n_out * fd== 1:\n",
    "                    layers += [Squeeze(-1)]\n",
    "        else:\n",
    "            if seq_len == 1:\n",
    "                layers += [nn.AdaptiveAvgPool1d(1)]\n",
    "            if not flatten and fd == seq_len:\n",
    "                layers += [Transpose(1,2), nn.Linear(n_in, n_out)]\n",
    "            else:\n",
    "                layers += [Reshape(), nn.Linear(n_in * seq_len, n_out * fd)]\n",
    "            layers += [Reshape(*shape)]\n",
    "\n",
    "        super().__init__(*layers)\n",
    "        \n",
    "create_lin_nd_head = lin_nd_head\n",
    "lin_3d_head = lin_nd_head # included for backwards compatiblity\n",
    "create_lin_3d_head = lin_nd_head # included for backwards compatiblity"
   ],
   "id": "34c7d66774c19b29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class HybridHCAN(nn.Module):\n",
    "    def __init__(self, c_in: int, c_out: int, seq_len: int = 500, d_model: int = 16, fc_channels: int = 128, custom_head=None, **kwargs):\n",
    "        \"\"\"\n",
    "        c_in: 输入通道数\n",
    "        c_out: 分类类别数\n",
    "        seq_len: 序列长度，默认值设为500（可根据实际数据调整）\n",
    "        d_model: 时间分支特征维度（ConvTranBackbone 输出的通道数）\n",
    "        fc_channels: 变量依赖分支（FCNPlus backbone）输出的通道数\n",
    "        custom_head: 接收 TSClassifier 传入的额外参数（此处不使用）\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 时间依赖分支（自定义，参考论文提取时序信息）\n",
    "        self.time_branch = ConvTranBackbone(c_in, seq_len, d_model=d_model, n_heads=8, dim_ff=256,\n",
    "                                             abs_pos_encode='tAPE', rel_pos_encode='eRPE', dropout=0.01)\n",
    "        # 变量间依赖分支（利用 tsai 的 FCNPlus，这里我们仅使用其 backbone 部分）\n",
    "        self.var_branch = FCNPlus(c_in, fc_channels)\n",
    "        # 定义全局池化：对每个分支的输出在时间维度上进行自适应平均池化\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        # 最终拼接后全连接分类层（输入维度为 d_model + fc_channels）\n",
    "        self.fc = nn.Linear(d_model + fc_channels, c_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 输入 x: [batch, c_in, seq_len]\n",
    "        # 时间依赖分支\n",
    "        time_feat = self.time_branch(x)               # 输出 shape: [batch, d_model, seq_len]\n",
    "        time_feat = self.global_pool(time_feat).squeeze(-1)  # 变为 [batch, d_model]\n",
    "        # 变量间依赖分支：使用 FCNPlus 的 backbone 部分提取特征\n",
    "        var_feat = self.var_branch.backbone(x)         # 输出 shape: [batch, fc_channels, seq_len]\n",
    "        var_feat = self.global_pool(var_feat).squeeze(-1)    # 变为 [batch, fc_channels]\n",
    "        # 拼接两个分支的特征\n",
    "        combined = torch.cat([time_feat, var_feat], dim=1)  # shape: [batch, d_model + fc_channels]\n",
    "        # 经过全连接层输出分类结果\n",
    "        out = self.fc(combined)\n",
    "        return out\n"
   ],
   "id": "45dbde53fd986bea",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c77f0ca3f4140fd0",
   "metadata": {},
   "source": [
    "tfms = [None, TSClassification()]\n",
    "batch_tfms = TSStandardize(by_sample=True)\n",
    "# 注意：这里将 arch 参数设置为我们自定义的 ConvTran，即使用以多头自注意力为核心的网络\n",
    "# model = TSClassifier(X, y.values, splits=splits, path='models', arch=HybridHCAN,\n",
    "#                      tfms=tfms, batch_tfms=batch_tfms, metrics=accuracy, cbs=ShowGraph())\n",
    "model = TSClassifier(X, y, splits=splits, path='models',\n",
    "                     arch=HybridHCAN,\n",
    "                     tfms=tfms, batch_tfms=batch_tfms,\n",
    "                     metrics=accuracy, cbs=ShowGraph())\n",
    "\n",
    "# 记录训练开始时间\n",
    "start_time = time.time()\n",
    "# 打印是否使用gpu\n",
    "print(torch.cuda.is_available())\n",
    "model.fit_one_cycle(30, 0.001)\n",
    "# 记录训练结束时间并输出训练时间\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"训练时间：{execution_time} 秒\")\n",
    "model.export(\"stage1.pkl\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63524e777eda7d6",
   "metadata": {},
   "source": [
    "print(model.model)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e18ee805e2b2223c",
   "metadata": {},
   "source": [
    "X2, y2 = df2xy(pd.concat([df1[176000:], df2[176000:], df3[176000:]], ignore_index=True), data_cols=None)\n",
    "X2 = X2.reshape(264, 500, 3)\n",
    "X2 = np.transpose(X2, (0, 2, 1))\n",
    "label2 = [0] * 88 + [1] * 88 + [2] * 88\n",
    "y2 = pd.DataFrame(label2)\n",
    "\n",
    "from tsai.inference import load_learner\n",
    "mv_clf = load_learner(r'.\\models\\stage1.pkl')\n",
    "\n",
    "start_time1 = time.time()\n",
    "probas, target, preds = model.get_X_preds(X2[:264], y2.values[:264])\n",
    "end_time1 = time.time()\n",
    "execution_time1 = end_time1 - start_time1\n",
    "print(f\"推理时间：{execution_time1} 秒\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f5cf0bef32382dd",
   "metadata": {},
   "source": [
    "print(f'accuracy: {skm.accuracy_score(target.to(\"cpu\").numpy().astype(int), preds.astype(int)):10.6f}')\n",
    "print(f'precision: {skm.precision_score(target.to(\"cpu\").numpy().astype(int), preds.astype(int), average=\"weighted\"):10.6f}')\n",
    "print(f'recall: {skm.recall_score(target.to(\"cpu\").numpy().astype(int), preds.astype(int), average=\"weighted\"):10.6f}')\n",
    "print(f'f1: {skm.f1_score(target.to(\"cpu\").numpy().astype(int), preds.astype(int), average=\"weighted\"):10.6f}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "974b7068a2ee4fb5",
   "metadata": {},
   "source": [
    "with open(r'.\\models\\stage1.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "file_size = os.path.getsize(r'.\\models\\stage1.pkl')\n",
    "print(f\"模型文件大小：{file_size / (1024 * 1024)} MB\")\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "params_count = count_parameters(model)\n",
    "print(f\"模型参数数量：{params_count // 1000}K\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7df2b8252c57744f",
   "metadata": {},
   "source": [
    "# 展示实际损伤分类和预测分类结果\n",
    "model.show_results()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# interp = ClassificationInterpretation.from_learner(model)\n",
    "# interp.plot_confusion_matrix()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(target.to(\"cpu\").numpy().astype(int), preds.astype(int))\n",
    "\n",
    "# 选择颜色方案\n",
    "cmap = 'Blues'  # 或者 'Greys', 'binary'\n",
    "\n",
    "# 使用 seaborn 绘制混淆矩阵\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=cmap,cbar=False,\n",
    "            annot_kws={\"size\": 18})  # 设置注释文本的字体大小\n",
    "\n",
    "# plt.title('Confusion Matrix', fontsize=20)  # 设置标题字体大小\n",
    "# plt.ylabel('True Label', fontsize=16)  # 设置y轴标签字体大小\n",
    "# plt.xlabel('Predicted Label', fontsize=16)  # 设置x轴标签字体大小\n",
    "\n",
    "# 增大刻度标签字体大小\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.show()"
   ],
   "id": "cca183b979215823",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.feature_importance()",
   "id": "f7ab30a430a2aa2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.show_probas()",
   "id": "aadb7a2d0b4c0e42",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
